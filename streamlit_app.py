#!/usr/bin/env python3
"""Streamlit UI for RAG Pipeline.

Usage:
    streamlit run streamlit_app.py
"""

import os
import sys
from pathlib import Path

import streamlit as st

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def get_available_providers() -> list[str]:
    """Get list of available LLM providers based on environment."""
    providers = []

    if os.getenv("OPENAI_API_KEY"):
        providers.append("openai")
    if os.getenv("VLLM_API_BASE"):
        providers.append("vllm")
    if os.getenv("SGLANG_API_BASE"):
        providers.append("sglang")

    # ollama is typically available locally
    providers.append("ollama")

    return providers if providers else ["openai", "vllm", "sglang", "ollama"]


def load_pipeline(
    provider: str,
    model: str | None,
    qna_db_path: str,
    tos_db_path: str,
    enable_verification: bool,
    verification_threshold: float,
):
    """Load RAG Pipeline."""
    import traceback

    from src.llm import create_llm_client
    from src.pipeline import RAGPipeline

    try:
        llm_kwargs = {}
        if model:
            llm_kwargs["model"] = model

        llm = create_llm_client(provider=provider, **llm_kwargs)

        pipeline = RAGPipeline(
            llm=llm,
            qna_db_path=qna_db_path,
            tos_db_path=tos_db_path,
            enable_verification=enable_verification,
            verification_threshold=verification_threshold,
        )

        return pipeline
    except Exception as e:
        st.error(f"íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘ ì—ëŸ¬: {e}")
        st.code(traceback.format_exc())
        raise


def render_sidebar():
    """Render sidebar with settings."""
    st.sidebar.title("âš™ï¸ ì„¤ì •")

    # LLM Settings
    st.sidebar.subheader("LLM ì„¤ì •")

    providers = get_available_providers()
    default_provider = os.getenv("LLM_PROVIDER", providers[0] if providers else "openai")

    provider = st.sidebar.selectbox(
        "LLM Provider",
        options=providers,
        index=providers.index(default_provider) if default_provider in providers else 0,
        help="ì‚¬ìš©í•  LLM ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”",
    )

    model = st.sidebar.text_input(
        "Model Name (optional)",
        value="",
        help="íŠ¹ì • ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì…ë ¥í•˜ì„¸ìš”",
    )

    # Verification Settings
    st.sidebar.subheader("ê²€ì¦ ì„¤ì •")

    enable_verification = st.sidebar.checkbox(
        "í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦ í™œì„±í™”",
        value=False,
        help="ì‘ë‹µì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤ (ì²˜ë¦¬ ì‹œê°„ ì¦ê°€)",
    )

    verification_threshold = st.sidebar.slider(
        "ê²€ì¦ ì„ê³„ê°’",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.05,
        help="ì´ ê°’ ë¯¸ë§Œì´ë©´ ê²€ì¦ ì‹¤íŒ¨ë¡œ í‘œì‹œ",
        disabled=not enable_verification,
    )

    # Database Paths
    st.sidebar.subheader("ë°ì´í„°ë² ì´ìŠ¤")

    qna_db_path = st.sidebar.text_input(
        "QnA DB ê²½ë¡œ",
        value="data/vectordb/qna",
    )

    tos_db_path = st.sidebar.text_input(
        "ToS DB ê²½ë¡œ",
        value="data/vectordb/tos",
    )

    return {
        "provider": provider,
        "model": model if model else None,
        "qna_db_path": qna_db_path,
        "tos_db_path": tos_db_path,
        "enable_verification": enable_verification,
        "verification_threshold": verification_threshold,
    }


def render_response_info(response):
    """Render response metadata in expandable section."""
    source_emoji = {
        "qna": "ğŸ“š",
        "tos": "ğŸ“œ",
        "no_context": "â“",
    }

    source_label = {
        "qna": "QnA ë°ì´í„°ë² ì´ìŠ¤",
        "tos": "ì•½ê´€ ë°ì´í„°ë² ì´ìŠ¤",
        "no_context": "ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ",
    }

    source_value = response.source.value

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            label="ì¶œì²˜",
            value=f"{source_emoji.get(source_value, 'ğŸ“„')} {source_label.get(source_value, source_value)}",
        )

    with col2:
        st.metric(
            label="ì‹ ë¢°ë„",
            value=f"{response.confidence:.0%}",
        )

    with col3:
        verification_status = "âœ… ê²€ì¦ë¨" if response.verified else "âš ï¸ ê²€ì¦ ì‹¤íŒ¨"
        st.metric(
            label="ê²€ì¦ ìƒíƒœ",
            value=verification_status,
            delta=f"{response.verification_score:.0%}",
        )

    # Citations
    if response.citations:
        st.info(f"ğŸ“ ì°¸ì¡°: {', '.join(response.citations)}")

    # Verification issues
    if response.verification_issues:
        with st.expander("âš ï¸ ê²€ì¦ ê²½ê³ ", expanded=True):
            for issue in response.verification_issues:
                st.warning(issue)

    # Context details
    if response.context:
        with st.expander("ğŸ“„ ì°¸ì¡°ëœ ì»¨í…ìŠ¤íŠ¸"):
            for i, ctx in enumerate(response.context, 1):
                st.markdown(f"**[{i}]** {ctx.get('document_title', ctx.get('question', 'N/A'))}")
                content = ctx.get("section_content", ctx.get("answer", ""))
                if len(content) > 500:
                    content = content[:500] + "..."
                st.text(content)
                st.divider()

    # Metadata
    if response.metadata:
        with st.expander("ğŸ”§ ë©”íƒ€ë°ì´í„°"):
            if response.metadata.get("verification_reasoning"):
                st.markdown(f"**ê²€ì¦ ìƒì„¸**: {response.metadata['verification_reasoning']}")
            if response.metadata.get("tokens_used"):
                st.markdown(f"**í† í° ì‚¬ìš©ëŸ‰**: {response.metadata['tokens_used']}")


def render_search_results(results: list[dict], search_type: str):
    """Render search results."""
    if not results:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.success(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")

    for i, r in enumerate(results, 1):
        score = r.get("score", 0)
        score_color = "green" if score >= 0.8 else "orange" if score >= 0.6 else "red"

        with st.expander(
            f"[{i}] Score: :{score_color}[{score:.3f}]",
            expanded=i == 1,
        ):
            if search_type == "qna":
                st.markdown(f"**Q:** {r.get('question', 'N/A')}")
                st.markdown(f"**A:** {r.get('answer', 'N/A')}")
            else:
                st.markdown(f"**ë¬¸ì„œ:** {r.get('document_title', 'N/A')}")
                st.markdown(f"**ì„¹ì…˜:** {r.get('section_title', 'N/A')}")
                st.markdown(f"**ë‚´ìš©:**")
                content = r.get("section_content", "")
                if len(content) > 500:
                    content = content[:500] + "..."
                st.text(content)


def main():
    st.set_page_config(
        page_title="RAG ì±—ë´‡",
        page_icon="ğŸ¤–",
        layout="wide",
    )

    st.title("ğŸ¤– RAG íŒŒì´í”„ë¼ì¸ ì±—ë´‡")
    st.caption("QnA ë° ì•½ê´€ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡")

    # Initialize session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "pipeline_loaded" not in st.session_state:
        st.session_state.pipeline_loaded = False

    # Render sidebar and get settings
    settings = render_sidebar()

    # Mode selection tabs
    tab_chat, tab_qna_search, tab_tos_search = st.tabs([
        "ğŸ’¬ ì±„íŒ…",
        "ğŸ” QnA ê²€ìƒ‰",
        "ğŸ“œ ì•½ê´€ ê²€ìƒ‰",
    ])

    # Load pipeline button in sidebar
    if st.sidebar.button("ğŸ”„ íŒŒì´í”„ë¼ì¸ ë¡œë“œ", use_container_width=True):
        try:
            with st.spinner("íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
                pipeline = load_pipeline(
                    provider=settings["provider"],
                    model=settings["model"],
                    qna_db_path=settings["qna_db_path"],
                    tos_db_path=settings["tos_db_path"],
                    enable_verification=settings["enable_verification"],
                    verification_threshold=settings["verification_threshold"],
                )
                st.session_state.pipeline = pipeline
                st.session_state.pipeline_loaded = True
                st.sidebar.success("íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ!")
                st.sidebar.info(f"QnA: {pipeline.qna_store.count()}ê°œ | ToS: {pipeline.tos_store.count()}ê°œ")
        except Exception as e:
            st.sidebar.error(f"ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.session_state.pipeline_loaded = False

    # Show pipeline status
    if st.session_state.pipeline_loaded:
        st.sidebar.success("âœ… íŒŒì´í”„ë¼ì¸ í™œì„±í™”ë¨")
    else:
        st.sidebar.warning("âš ï¸ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”")

    # Chat tab
    with tab_chat:
        if not st.session_state.pipeline_loaded:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”.")
        else:
            # Chat history in scrollable container
            chat_container = st.container(height=500)

            with chat_container:
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
                        if message["role"] == "assistant" and "response_data" in message:
                            render_response_info(message["response_data"])

            # Chat input (outside container, stays at bottom)
            if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
                # Add user message
                st.session_state.messages.append({"role": "user", "content": prompt})

                # Generate response
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        response = st.session_state.pipeline.query(prompt)

                        # Save to history
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response.answer,
                            "response_data": response,
                        })
                    except Exception as e:
                        error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_msg,
                        })

                st.rerun()

            # Clear chat button
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì§€ìš°ê¸°"):
                st.session_state.messages = []
                st.rerun()

    # QnA Search tab
    with tab_qna_search:
        if not st.session_state.pipeline_loaded:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”.")
        else:
            st.subheader("QnA ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰")

            col1, col2 = st.columns([3, 1])
            with col1:
                qna_query = st.text_input(
                    "ê²€ìƒ‰ì–´",
                    key="qna_search_input",
                    placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                )
            with col2:
                qna_n_results = st.number_input(
                    "ê²°ê³¼ ìˆ˜",
                    min_value=1,
                    max_value=20,
                    value=5,
                    key="qna_n_results",
                )

            if st.button("ğŸ” QnA ê²€ìƒ‰", key="qna_search_btn"):
                if qna_query:
                    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                        results = st.session_state.pipeline.search_qna(
                            qna_query, n_results=qna_n_results
                        )
                        render_search_results(results, "qna")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ToS Search tab
    with tab_tos_search:
        if not st.session_state.pipeline_loaded:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”.")
        else:
            st.subheader("ì•½ê´€ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰")

            col1, col2 = st.columns([3, 1])
            with col1:
                tos_query = st.text_input(
                    "ê²€ìƒ‰ì–´",
                    key="tos_search_input",
                    placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                )
            with col2:
                tos_n_results = st.number_input(
                    "ê²°ê³¼ ìˆ˜",
                    min_value=1,
                    max_value=20,
                    value=5,
                    key="tos_n_results",
                )

            if st.button("ğŸ” ì•½ê´€ ê²€ìƒ‰", key="tos_search_btn"):
                if tos_query:
                    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                        results = st.session_state.pipeline.search_tos(
                            tos_query, n_results=tos_n_results
                        )
                        render_search_results(results, "tos")
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
