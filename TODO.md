# TODO

## Evaluation Pipeline ê°œì„  (Priority Order)

### ğŸ”´ Critical

- [x] **1. í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë„ì…**: BLEU ê³„ì‚° ì‹œ space split ëŒ€ì‹  í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©. í˜„ì¬ "í•œêµ­íˆ¬ìì¦ê¶Œì—ì„œ"ê°€ ë‹¨ì¼ í† í°ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ n-gram ë§¤ì¹­ì´ ë¶€ì •í™•í•¨
  - íŒŒì¼: `src/evaluation/evaluator.py:156-217`
  - ë°©ì•ˆ: kiwipiepy (ê²½ëŸ‰, ìˆœìˆ˜ Python) ë˜ëŠ” konlpy ì‚¬ìš©
  - **ì™„ë£Œ**: kiwipiepy ë„ì…, singleton íŒ¨í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”

- [x] **2. ë°°ì¹˜ í‰ê°€ ë³‘ë ¬ ì²˜ë¦¬**: 50ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ + LLM Judge ì‚¬ìš© ì‹œ ìˆœì°¨ ì²˜ë¦¬ë¡œ ì‹œê°„ ê³¼ë‹¤ ì†Œìš”
  - íŒŒì¼: `src/evaluation/runner.py:275-315`
  - ë°©ì•ˆ: asyncio + ThreadPoolExecutor ë˜ëŠ” concurrent.futures í™œìš©
  - **ì™„ë£Œ**: ThreadPoolExecutor ê¸°ë°˜ ë³‘ë ¬ ì‹¤í–‰, `--parallel` / `--max-workers` CLI ì˜µì…˜ ì¶”ê°€

- [x] **3. LLM Judge JSON íŒŒì‹± ì•ˆì •í™”**: íŒŒì‹± ì‹¤íŒ¨ ì‹œ 0.0 ì ìˆ˜ ë¶€ì—¬ê°€ ê²°ê³¼ ì™œê³¡ ìœ ë°œ
  - íŒŒì¼: `src/evaluation/llm_judge.py:244-291`
  - ë°©ì•ˆ: Retry ë¡œì§, Partial parsing, Structured output mode
  - **ì™„ë£Œ**: Exponential backoff retry, regex fallback íŒŒì‹±, ì—ëŸ¬ ì‹œ neutral score (3.0) ì‚¬ìš©

### ğŸŸ¡ High Priority

- [x] **4. Context Overlap ë©”íŠ¸ë¦­ í™œì„±í™”**: `compute_context_overlap` ì •ì˜ë˜ì–´ ìˆìœ¼ë‚˜ ë¯¸ì‚¬ìš©
  - íŒŒì¼: `src/evaluation/evaluator.py:249-285`
  - ë°©ì•ˆ: EvaluationMetricsì— context_recall/precision ì¶”ê°€
  - **ì™„ë£Œ**: context_recall, context_precision í•„ë“œ ì¶”ê°€, evaluate()ì—ì„œ expected_sources ì§€ì›

- [x] **5. Embedding Model ì‹±ê¸€í†¤í™”**: ê° Evaluatorê°€ ë³„ë„ ëª¨ë¸ ë¡œë“œë¡œ ë©”ëª¨ë¦¬ ë‚­ë¹„
  - íŒŒì¼: `src/evaluation/evaluator.py:121-132`
  - **ì™„ë£Œ**: `_get_embedding_model()` ì‹±ê¸€í†¤ íŒ¨í„´ ë„ì…

- [x] **6. Judge Model Diversity ê¸°ë³¸ê°’ ê°•í™”**: strict_diversity=Falseê°€ ê¸°ë³¸, ê°™ì€ ëª¨ë¸ í‰ê°€ í—ˆìš©
  - íŒŒì¼: `src/evaluation/llm_judge.py:432-440`
  - **ì™„ë£Œ**: `strict_diversity=True`ë¡œ ê¸°ë³¸ê°’ ë³€ê²½

### ğŸŸ¢ Medium Priority

- [x] **7. ë©”íŠ¸ë¦­ ìŠ¤ì¼€ì¼ í‘œì¤€í™”**: similarity/bleuëŠ” 0-1, llm_judgeëŠ” 1-5ë¡œ í˜¼ì¬
  - **ì™„ë£Œ**: ì •ê·œí™”ëœ LLM Judge ë©”íŠ¸ë¦­ ì¶”ê°€ (mean_llm_*_normalized, 0-1 ìŠ¤ì¼€ì¼)
- [x] **8. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€**: LLMJudge, FrontierClient í…ŒìŠ¤íŠ¸ ë¶€ì¬
  - **ì™„ë£Œ**: 39ê°œ í…ŒìŠ¤íŠ¸ (LLMJudgeComprehensive, JudgeModelSelector, ContextOverlapMetrics ë“±)
- [x] **9. Dataset Schema Validation**: Pydantic ê¸°ë°˜ ê²€ì¦ ì¶”ê°€
  - **ì™„ë£Œ**: `src/evaluation/schemas.py` ì¶”ê°€, EvaluationTestCase/EvaluationDataset ëª¨ë¸
- [x] **10. Faithfulness ëª…ì¹­ ëª…í™•í™”**: verifier vs judge êµ¬ë¶„ ê°œì„ 
  - **ì™„ë£Œ**: verifier_faithfulness vs judge_context_faithfulness ëª…ëª… ê·œì¹™ ì ìš©

---

## RAG Pipeline ê¸°ëŠ¥ ì œì•ˆ

- Adaptive Thresholding: í˜„ì¬ ê³ ì • ì„ê³„ê°’(DEFAULT_QNA_THRESHOLD, DEFAULT_TOS_THRESHOLD). ì¤‘ê°„ ì˜ì—­ì€ "ê·¼ê±° ì œí•œ ë‹µë³€/ì¬ì§ˆë¬¸/ìƒë‹´ì› ì—°ê²°"ë¡œ ë¶„ê¸°í•˜ëŠ” ê²Œ ì•ˆì „í•¨: src/pipeline/rag_pipeline.py
- HyDE/Query Expansion: ToSëŠ” ì¥ë¬¸ì˜ ë²•ë¥  ë¬¸ì²´ë¼ ì§§ì€ ì§ˆì˜ ë§¤ì¹­ì´ ì•½í•¨. src/pipeline/rag_pipeline.pyì—ì„œ ToS ê²€ìƒ‰ ì§ì „ ì§ˆì˜ í™•ì¥ í›„ ê²€ìƒ‰(ë˜ëŠ” ë³‘ë ¬ ê²€ìƒ‰) ì¶”ê°€ ê¶Œì¥.
- Citation-to-Context ë§¤í•‘ ê°•í™”: í˜„ì¬ ì¸ìš© íŒ¨í„´ ë§¤ì¹­ì€ ì„¹ì…˜ ì œëª© ê¸°ë°˜ ë¶€ë¶„ ì¼ì¹˜. ì¡°í•­ ë²ˆí˜¸/ì œëª© í‘œì¤€í™” í…Œì´ë¸”ì„ ë§Œë“¤ì–´ ì•ˆì •ì„± í–¥ìƒ: src/verifier/verifier.py, src/tos_store.py
- Chunking ê³ ë„í™”: ToSChunkerê°€ ì„¹ì…˜ ê¸°ë°˜ì´ê¸´ í•˜ë‚˜ ìµœëŒ€ ê¸¸ì´ ì ˆë‹¨ê³¼ parent_contextëŠ” ê³ ì •. ë¬¸ì¥ ê²½ê³„/ì˜¤ë²„ë© ê¸°ë°˜ semantic chunking ì¶”ê°€í•˜ë©´ ì •í™•ë„ ê°œì„ : src/vectorstore/tos_store.py
- Query Normalization (Korean): ì¡°ì‚¬/ì¢…ê²°ì–´ë¯¸ ì •ê·œí™”, ìˆ«ì/ì¡°í•­ íŒ¨í„´ ì •ê·œí™” ì „ì²˜ë¦¬ë¥¼ ì¶”ê°€í•´ ê²€ìƒ‰ í’ˆì§ˆì„ ì˜¬ë¦´ ìˆ˜ ìˆìŒ: src/pipeline/rag_pipeline.py, src/tos_search/rule_matcher.py
- Telemetry/Trace: ì‘ë‹µë§ˆë‹¤ retrieval scores, ì„ íƒëœ ë¬¸ì„œ, verification ê²°ê³¼ë¥¼ êµ¬ì¡°í™” ë¡œê·¸ë¡œ ë‚¨ê¸°ë©´ ìš´ì˜ ì§„ë‹¨ì´ ì‰¬ì›€: src/pipeline/rag_pipeline.py
- [DONE] Human-in-the-loop QnA í™•ì¥: src/vectorstore/backfill.py + scripts/backfill_agent_answers.py êµ¬í˜„ ì™„ë£Œ
