default_model: multilingual-e5-large

models:
  multilingual-e5-large:
    name: intfloat/multilingual-e5-large
    type: e5
    dimension: 1024
    max_seq_length: 512
    normalize: true
    description: "Best quality for Korean, slower"

  multilingual-e5-base:
    name: intfloat/multilingual-e5-base
    type: e5
    dimension: 768
    max_seq_length: 512
    normalize: true
    description: "Good balance of quality and speed"

  qwen3-embedding-8b:
    name: Qwen/Qwen3-Embedding-8B
    type: standard
    dimension: 4096
    max_seq_length: 32768
    normalize: true
    description: "Best quality for Korean, long context (32K), slower"

  qwen3-embedding-0.6b:
    name: Qwen/Qwen3-Embedding-0.6B
    type: standard
    dimension: 1024
    max_seq_length: 32768
    normalize: true
    description: "Lightweight Qwen3 embedding, long context (32K), fast"

  bge-m3:
    name: BAAI/bge-m3
    type: standard
    dimension: 1024
    max_seq_length: 8192
    normalize: true
    description: "Long context support, good Korean"

  paraphrase-multilingual:
    name: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
    type: standard
    dimension: 768
    max_seq_length: 128
    normalize: true
    description: "Fastest, decent Korean"

device: null  # auto-detect (cuda > mps > cpu)

reranker:
  enabled: false
  candidates: 20
  top_k: null
  weight: 0.3
  default_model: bge-reranker-v2-m3
  models:
    bge-reranker-v2-m3:
      name: BAAI/bge-reranker-v2-m3
      max_seq_length: 1024
      description: "Multilingual reranker, stronger accuracy"
    ms-marco-minilm:
      name: cross-encoder/ms-marco-MiniLM-L-6-v2
      max_seq_length: 512
      description: "Fast reranker for low latency"
  device: null  # auto-detect (cuda > mps > cpu)
  batch_size: 32
